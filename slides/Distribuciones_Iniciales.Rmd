---
title: "Métodos Estadísticos con R"
subtitle: "CODD"
author: "Gibrán Peniche"
date: "(versión 0.0.1) - 2020/06/25"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["xaringan-themer.css", "style.css"]
    nature:
      highlightStyle: github
      highlightLines: TRUE
      countIncrementalSlides: TRUE
      self_contained: TRUE
      ratio: '16:9'
    seal: false
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(eval = TRUE)
```

class: title-slide, middle

.pull-left[ 
# Métodos Estadísticos Bayesianos con R
## Distribuciones Iniciales y Funciones de Pérdida
### Gibrán Peniche
### v. 0.0.1
### 2020-07-21
####  <i class="fab fa-github"></i> [jgpeniche](https://github.com/jgpeniche)
####  <i class="fab fa-twitter"></i> [PenicheGibran](https://twitter.com/PenicheGibran)
####  <i class="fab fa-google"></i> jgpeniche@gmail.com

]

.pull-right[

![](figs/logo_g.png)

]

---
# La sesión pasada...

--

Migramos de *maximizar* la **utilidad** $u_0$ a *minimizar* la **pérdida** $\mathcal{L}$, rescatando la noción de "distancia" del valor real $\theta$

--

A partir de los Axiomas de Coherencia dedujimos un algoritmo de 3 pasos para nuestro problema de inferencia:

--

1. Definir una función de pérdida $\mathcal{L}$ y cuantificar la incertidumbre asociada a $\theta$ con $f(\theta)$ *a priori*

--
    
  1.1. En caso de existir información adicional (datos - verosimilitud) incorporarlos a través de Teorema de Bayes y obtener $P(\theta| X_{(n)})$
  
--

2. Minimzar la *pérdida esperada* $\int_{\Theta} \mathcal{L(\theta, \hat{\theta})}P(\theta| X_{(\underline{n})})$ (en el caso **discreto**: $\sum_{\Theta} \mathcal{L(\theta, \hat{\theta})}P(\theta| X_{(\underline{n})})$ )

--

3. Escoger $d_{\hat{\theta}}$ que minimice dicha pérdida

---

# Agenda

--

1. Entender las repercusiones de distintas funciones de pérdida

--

  1.1. Pérdida Cuadrática
  
--

  1.2. Pérdida Absoluta
  
--

  1.3. Pérdida (0,1)
  
--

2. Distribuciones iniciales

---

class: inverse, center, middle
# 1

--

# Funciones de Pérdida

---

class: center, middle
--

# Pérdida Cuadrática

---

# Pérdida Cuadrática

--

Sea $\mathcal{L}(\hat{\theta}, \theta) = (\hat{\theta} - \theta)^2$

--

$\underset{\theta}{\arg\min} \quad \int_{\Theta} (\hat{\theta} - \theta)^2 P(\theta|X_{(\underline{n})})d \theta$

--

Pero $$\int_{\Theta} (\hat{\theta} - \theta)^2 P(\theta|X_{(\underline{n})})d \theta = \hat{\theta}^2 \int_{\Theta} P(\theta|X_{(\underline{n})})d \theta \quad -2\hat{\theta} \int_{\Theta} \theta P(\theta|X_{(\underline{n})})d \theta \quad + \int_{\Theta} \theta^2 P(\theta|X_{(\underline{n})})d \theta$$

--

Además sabemos que $\int_{\Theta} P(\theta|X_{(\underline{n})})d \theta = 1$

---

# Pérdida Cuadrática


Tomando la derivada con respecto de $\hat{\theta}$ e igualando a 0

$$\frac{\partial}{\partial \theta} = 2 \hat{\theta}  - 2 \int_{\Theta} \theta P(\theta|X_{(\underline{n})})d \theta = 0$$

--

$\Longleftrightarrow$

$$\hat{\theta} = \int_{\Theta} \theta P(\theta|X_{(\underline{n})})d \theta = \mathbb{E}[\theta|X_{(\underline{n})}]$$

---

class: center, middle
# Pérdida Absoluta

---

# Pérdida Absoluta

--

Sea $\mathcal{L}(\hat{\theta}, \theta) = |\hat{\theta} - \theta|$

--

$\underset{\theta}{\arg\min} \quad \int_{\Theta} |\hat{\theta} - \theta| P(\theta|X_{(\underline{n})})d \theta$

--

Pero $$\int_{\Theta} |\hat{\theta} - \theta| P(\theta|X_{(\underline{n})})d \theta =  \int_{-\infty}^{\theta} (\hat{\theta}-\theta)P(\theta|X_{(\underline{n})})d \theta \quad + \int_{\theta}^{\infty} (\theta - \hat{\theta})P(\theta|X_{(\underline{n})})d \theta$$

---

# Pérdida Absoluta

Tomando la derivada con respecto a $\theta$ e igualando a 0


$$\int_{-\infty}^{\hat{\theta}} P(\theta|X_{(\underline{n})}) = \int_{\hat{\theta}}^{\infty} P(\theta|X_{(\underline{n})})$$

--

$\Longleftrightarrow$

$$ \hat{\theta} = mediana$$
---

class: center, middle
# Pérdida (0,1)

---

# Pérdida (0,1)

--

Sea $$\mathcal{L} =\left\{\begin{array}{ll} 1 & \quad |\hat{\theta} - \theta| > \epsilon \\ 0 & \quad  |\hat{\theta} - \theta| \leq \epsilon \end{array}\right. = 1- \delta(\hat{\theta- \theta})$$

Donde $delta$ denota la *delta de Dirc*

--

$\longrightarrow$

$$\int_{\Theta} ( 1 - \delta(\hat{\theta}- \theta))P(\theta|X_{(\underline{n})})d \theta = 1-\int_{\Theta}\delta(\hat{\theta}-\theta )P(\theta|X_{(\underline{n})})d \theta = 1 - P(\theta|X_{(\underline{n})})$$

--

El problema de minimizar la función objetivo es equivalente a maximizar la densidad $\therefore$

--

$$ \quad \hat{\theta} = moda $$

---

class: inverse, center, middle
# 2

--
 
# Distribuciones Iniciales

---

# ¿Cómo funciona el proceso de inferencia Bayesiano?

--

- $P(\theta| X_{(\underline{n})}) \propto \mathbb{L}(\theta|X_{(\underline{n})})\cdot P(\theta)$ es una manera conciliar nuestra **incertidumbre** sobre el parámetro de interés y la información que aportan los *datos*

--

Gráficamente tenemos lo siguiente

```{r prior, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center', out.width=300}
library(tidyverse)
library(latex2exp)

set.seed(123)

priors <- tibble(
  x = seq(from = 0,to = 10, length.out = 100)) 


priors <- priors %>% 
  mutate(prior1 = dnorm(x, mean = 2.5), 
         likelihood = dnorm(x, mean = 7.5),
         posterior1 = dnorm(x, mean = 5))



priors %>% 
  ggplot() +
  aes(x = x) +
  expand_limits(y = c(0,.7))+
  geom_line(aes(y = prior1), col = 'blue') +
  annotate( geom = 'curve', x = 1, y = .3, xend = 1.5, yend = 0.27,
            curvature = .3, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = .5, y = .31, 
           label = 'P(theta)', parse = TRUE, size = 8) +
  theme_minimal() +
  labs(x = "", y = "")

```

---

# ¿Cómo funciona el proceso de inferencia Bayesiano?

- $P(\theta| X_{(\underline{n})}) \propto \mathbb{L}(\theta|X_{(\underline{n})})\cdot P(\theta)$ es una manera conciliar nuestra **incertidumbre** sobre el parámetro de interés y la información que aportan los *datos*


Gráficamente tenemos lo siguiente

```{r prior1, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center', out.width=300}

priors %>% 
  ggplot() +
  aes(x = x) +
expand_limits(y = c(0,.7))+
  geom_line(aes(y = prior1), col = 'blue') +
  annotate( geom = 'curve', x = 1, y = .3, xend = 1.5, yend = 0.27,
            curvature = .3, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = .5, y = .31, 
           label = 'P(theta)', parse = TRUE, size = 8) +
  geom_line(aes(y = likelihood), col = 'green') +
  annotate( geom = 'curve', x = 9, y = .3, xend = 8.5, yend = 0.27,
            curvature = .3, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = 9.7, y = .32, parse = TRUE, size = 8,
          label = TeX('$L(\\theta | X_{(\\underline{n})})$')) +
  theme_minimal() +
  labs(x = "", y = "")

```

---

# ¿Cómo funciona el proceso de inferencia Bayesiana?

- $P(\theta| X_{(\underline{n})}) \propto \mathbb{L}(\theta|X_{(\underline{n})})\cdot P(\theta)$ es una manera conciliar nuestra **incertidumbre** sobre el parámetro de interés y la información que aportan los *datos*


Gráficamente tenemos lo siguiente

```{r prior2, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center', out.width=300}

priors %>% 
  ggplot() +
  aes(x = x) +
  expand_limits(y = c(0,.7))+
  geom_line(aes(y = prior1), col = 'blue') +
  annotate( geom = 'curve', x = 1, y = .3, xend = 1.5, yend = 0.27,
            curvature = .3, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = .5, y = .31, 
           label = 'P(theta)', parse = TRUE, size = 8) +
  geom_line(aes(y = likelihood), col = 'green') +
  annotate( geom = 'curve', x = 9, y = .3, xend = 8.5, yend = 0.27,
            curvature = .3, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = 9.7, y = .32, parse = TRUE, size = 8,
          label = TeX('$L(\\theta | X_{(\\underline{n})})$')) +
  geom_line(aes(y = posterior1), col = 'orange') +
  annotate( geom = 'curve', x = 5, y = .5, xend = 5, yend = 0.45,
            curvature = 0, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = 5, y = .6,
           label = TeX('$P(\\theta | X_{(\\underline{n})})$'), parse = TRUE, size = 8) +
  theme_minimal() +
  labs(x = "", y = "")

```

---

class: center, middle
# La pregunta es: ¿Cómo determinamos una $P(\theta)$ apropiada?

---

class: center, middle, inverse
# 2

--

# Distribuciones iniciales

---

# Distribuciones iniciales 

--

**R:** Depende...

--

- Recordemos que en el contexto del problema de inferencia $P(\theta)$ cuantifca nuestra incertidumbre alrededor del parámetro de interés

--

- En este sentido las preguntas que debe responder la elección de alguna distribución en particular debe responder al menos las siguientes preguntas:

--

  1. ¿ $P(\theta)$ es congruente con el espacio parametral $\Theta$?
  
--

  2. ¿Está centrada alrededor de algún valor?
  
--

  3. ¿Es simétrica?
  
--

  4. ¿Qué tanta variabilidad presenta? Ó en otras palabras ¿Cuál es mi nivel de certidumbre medido en términos (p.e.) de la desviación estándar?

--

- Dependiendo de estas características en particular de la distribución inicial y su interacción con la verosimilutud la distribución posterior tendrá diferentes caracterísitcas

---

# Distribuciones iniciales

--

- De acuerdo al grado de "certeza" del conocimiento *a priori* sobre el paramtero historicamente se les ha clasificado como distribuciones **informatvas** o **no informativas** (ó distribuciones **de referencia** en literatura más reciente)

--

```{r informativa2, echo = FALSE, out.width=400, fig.align='center', out.width=300, warning=FALSE}

priors <- priors %>% 
  mutate(prior2 = dnorm(x,mean = 2.5, sd = 0.3),
         posterior2 = dnorm(x, mean = 3.5, sd = .7))

priors %>% 
  ggplot() +
  aes(x = x) +
  expand_limits(y = c(0,.7))+
  geom_line(aes(y = prior2), col = 'blue') +
  annotate( geom = 'curve', x = 1, y = .3, xend = 1.5, yend = 0.27,
            curvature = .3, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = .5, y = .31, 
           label = 'P(theta)', parse = TRUE, size = 8) +
  geom_line(aes(y = likelihood), col = 'green') +
  annotate( geom = 'curve', x = 9, y = .3, xend = 8.5, yend = 0.27,
            curvature = .3, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = 9.7, y = .3, parse = TRUE, size = 8,
          label = TeX('$L(\\theta | X_{(\\underline{n})})$')) +
  geom_line(aes(y = posterior2), col = 'orange') +
   annotate( geom = 'curve', x = 3.5, y = .7, xend = 3.5, yend = 0.6,
            curvature = 0, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = 3.8, y = .8, 
          label = TeX('$P(\\theta | X_{(\\underline{n})})$'), parse = TRUE, size = 8) +
  theme_minimal() +
  labs(x = "", y = "",
       title = 'Distribución Inicial Informativa')

```

---

# Distribuciones iniciales

--

- De acuerdo al grado de "certeza" del conocimiento *a priori* sobre el paramtero historicamente se les ha clasificado como distribuciones **informatvas** o **no informativas** (ó distribuciones **de referencia** en literatura más reciente)

--

```{r informativa3, echo = FALSE, out.width=300, fig.align='center', warning=FALSE}

priors <- priors %>% 
  mutate(prior3 = dunif(x,min = 0, max = 10),
         posterior3 = dnorm(x, mean = 6.5, sd = .7))

priors %>% 
  ggplot() +
  aes(x = x) +
  expand_limits(y = c(0,.7))+
  geom_line(aes(y = prior3), col = 'blue') +
  annotate( geom = 'curve', x = .7, y = .25, xend = 1.5, yend = 0.12,
            curvature = .3, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = .5, y = .31, 
           label = 'P(theta)', parse = TRUE, size = 8) +
  geom_line(aes(y = likelihood), col = 'green') +
  annotate( geom = 'curve', x = 9, y = .3, xend = 8.5, yend = 0.27,
            curvature = .3, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = 9.7, y = .3, parse = TRUE, size = 8,
          label = TeX('$L(\\theta | X_{(\\underline{n})})$')) +
  geom_line(aes(y = posterior3), col = 'orange') +
   annotate( geom = 'curve', x = 6.5, y = .65, xend = 6.5, yend = 0.6,
            curvature = 0, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = 6.5, y = .71, 
           label = TeX('$P(\\theta | X_{(\\underline{n})})$'), parse = TRUE, size = 8) +
  theme_minimal() +
  labs(x = "", y = "",
       title = 'Distribución Inicial de Referencia')

```
---

# Distribuciones Iniciales de Referencia

--

- Uno de los motivos por los cuales Ronald A. Fisher, criticaba a la escuela Bayesiana era precisamente este elemento subjetivo intrínseco en la asignación de probabilidades *a priori* (Recordemos que la escuela frecuentista parte de postivismo de Augusto Comte por lo cual la fuente última de conocmiento es la experiencia)

--

- Además la asignación de probabilidades a través de la distribución uniforme es dificil de manipular al realizar la multiplcación de $\mathbb{L}(\theta |X_{(\underline{n})}) \cdot P(\theta)$

--

- Esto plantea un reto para la escuela bayesiana para encontrar un método de generar distribuciones de referencia. tales que se le diera "prioridad" a los datos y hacer la asignación *a priori* lo menos subjetiva posible

---

class: center, middle
# Pregunta: ¿Existe algún método para generar distribuciones de referencia que no sea la distribución uniforme?

---

# Distribución Inicial de Jeffreys

--

- Sir Harold Jeffreys, fue un matemático, estadístico, geofísico y astrónomo británico es uno de los padres de la estadística Bayesiana

--

- Jeffreys concluyó que una opción posible para generar distribuciones de referencia para cualquier modelo es la siguiente: $$P(\theta) \propto I(\theta)^{\frac{1}{2}}$$

--

- $I(\theta)$ denota la **Información de Fisher**, es decir $$I(\theta) \propto -\mathbb{E}[\frac{\partial^2}{\partial \theta^2}lnf(x|\theta)]$$

---

# Resiliencia de la Verosimilitud

--

- A pesar de que parece que el investigador puede forzar cierta distribución *a- posteriori* a través de la distribución *a-priori*, existe un umbral a partir del cual la interacción con la verosimilitud se queda fija ante distribucione sinciales 'locas'

--

- Al análisis (que debe acompañar a cualquier análisis Bayesiano) del umbral dónde la distribución *a posteriori* deja de cambiar ante distribuciones iniciales "extremas" se le llama **resilencia de la verosismilitud** (Haro _ Peniche, 2020)

--

- Esto implica que hay un "seguro" sobre que tanto puede el investigador incorporar información *a-priori* al experimento

---


---
# Ejemplo Práctico

--

- Sea $x_i \sim Bernoulli(\theta)$ y $\theta \sim U(0,1)$

--

**Pregunta:** ¿Cómo se distribuye $P(\theta | X_{(\underline{n})})$?

--

**R:** Sabemos que $$P(\theta | X_{(\underline{n})}) \propto \mathbb{L}(\theta | X_{(\underline{n})}) P(\theta)$$

--

Pero...

$$\mathbb{L}(\theta|X_{(\underline{n})}) = \prod_{i = 1}^{n}f(x_i|\theta)$$
--

Como $x_i \sim Bernoulli(\theta) \quad \Longrightarrow$

$$\mathbb{L}(\theta|X_{(\underline{n})}) = \theta^{\sum_{I}x_i}(1-\theta)^{n - \sum_{I}x_i}$$

---

# Ejemplo Práctico

$\Longrightarrow$

$$p(\theta | x_{}(\underline{n})) \propto  \theta^{\sum_{I}x_i}(1-\theta)^{n- \sum_{n - \sum_{}I}} \frac{1}{\theta} \mathbb{1}_{(0,\theta)}\mathbb{1}_{(0,1)}$$
--

**R:** No hay respuesta cerrada

---

# Ejemplo Práctico

--

- Sea $x_i \sim Bernoulli(\theta)$ y $\theta \sim \beta(2,2)$

--

- $$p(\theta | x_{}(\underline{n})) \propto  \theta^{\sum_{I}x_i}(1-\theta)^{n- \sum x_i} \frac{\theta^{\alpha - 1}(1- \theta)^{\beta - 1}}{B(\alpha, \beta)}$$

--

- El operador $\propto$ implica que todo lo que no se realacione con el parámetro $\theta$ puede ser tratado como una constante

--

- $$p(\theta | x_{}(\underline{n})) \propto  \theta^{\sum_{I}x_i + \alpha - 1}(1-\theta)^{n- \sum x_i + \beta - 1}$$

--

-  $$P(\theta | X_{(\underline{n}))} \propto  \beta(\theta | a = \sum_I x_i + \alpha, b = n - \sum x_i + \beta)$$

--

¿Qué elecciones de $P(\theta)$ y $x_i \sim f(x | \theta)$ resultan en una familia parametrica fácil de manipular?

---


# ¿Qué sigue?

--

1. Familias conjugadas
