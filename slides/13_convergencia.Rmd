---
title: "Métodos Estadísticos con R"
subtitle: "CODD"
author: "Gibrán Peniche"
date: "(versión 0.0.1) - 2020/06/25"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["xaringan-themer.css", "style.css"]
    nature:
      highlightStyle: github
      highlightLines: TRUE
      countIncrementalSlides: TRUE
      self_contained: TRUE
      ratio: '16:9'
    seal: false
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(eval = TRUE)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(fig.align = 'center')
library(tidyverse)
library(gt)
library(patchwork)
library(tidybayes)
library(latex2exp)

```

class: title-slide, middle

.pull-left[ 
# Métodos Estadísticos Bayesianos con R
## Diagnóstico de Convergencia MCMC
### Gibrán Peniche
### v. 0.0.1
### 2020-11-05
####  <i class="fab fa-github"></i> [jgpeniche](https://github.com/jgpeniche)
####  <i class="fab fa-twitter"></i> [PenicheGibran](https://twitter.com/PenicheGibran)
####  <i class="fab fa-google"></i> jgpeniche@gmail.com

]

.pull-right[

![](figs/logo_g.png)

]

---

# La sesión pasada...

--

- Presentamos la caracterizción de las cadenas de Markov para espacios de estados continuos

--

- Presentamos 3 algortimos de simulación de Monte Carlo con Cadenas de MArkov 

--

  1. Muestreo de Gibbs

--

  2. Metrópolis Hastings

--

  3. Monte Carlo Hamiltoneano

---

# Agenda

--
  
  1. Diagnóstico de Convergencia de MCMC
  
--
  
  2. Ejemplo práctico muestreo de Gibbs

---

class: inverse, center, middle

# 1

--

# Diagnóstico de Convergencia MCMC

---

# Diagnóstico de Convergencia MCMC

--

Si bien habiendo probado las propiedades teóricas de un algortimo de simulación que define una Cadena de Markov $\{\theta^{(n)} \}_{n \geq 0}$ (homegeneidad, aperiodidicad, ergodicidad, recurrencia de Harris, etc...) hay resultados fuertes que nos garantizan la convergencia del mismo a $\pi(\theta)$ en la práctica, ya que estamos utilizando numero pseudo-aleatorios y no hay manera de determinar el umbral $n^*$ de convergencia, es necesario evaluar el proceso de simulación

--

Este no es un problema trivial, la discusión hoy en día sigue abierta y a la fecha inconclusa

--

A continuación estudiaremos una serie de tecnicas formales e informales para diagnosticar la convergencia de los algoritmos MCMC y por transitividad, la validez de nuestras inferencias

---
class: center, middle

# Diagnóstico (Informal) de Convergencia

---

# Diagnóstico (Informal) de Convergencia

--

**Diagnóstico Gráfico** (Gelfand y Smith, 1990)

--

  1. Graficar los histogramas de todos los componentes de $\theta$ después del **periodo de calentamiento** y graficarlos cada $k$ pasos de la cadena: Se acepta la cnvergencia si los histogramas son indistingbles los unos de los otros
  
--

  2. Graficar Trayecorias y Promedios Ergódicos: Graficar la trayetoria de la simulación para $\theta$ y su promedio ergódico. Si estos presetan el mismo comportamiento cualitativo (estabilidad) a lo largo de $t$ se acepta la convergencia
  
--

Lamentablemente estas medidas no son un resultado teórico y puede haber factores (como la escala) que instroduzcan distorciones

---

class: center, middle

# Diagnóstico (Formal) de Convergencia

---

# Diagnóstico (Formal) de Convergencia

--

1. Muestreo por $m^*$ retrazos: este método busca controlar el error del Estimador de Monte Carlo $t(\theta)$ mediante el TLC para cadenas de Markov y elergir un tamaño de muestra $n^*$ tal que los intervalos posteriores sean creibles a cierto nivel (ver Gamerman, p. 162)

--

2. Series de tiempo: Considere $n_b + n_a < n$ donde despupes de $m$ pasos de entrenamiento $\psi_a$ y $\psi_b$ son los promedios (ergódicos) después del periodo de convergencia. Sea $Z_G = \frac{\psi_a - \psi_b}{\sqrt{Var(\psi_a) + Var(\psi_b)}} \xrightarrow{d} N(0,1)$. Esto sugiere que diferecnias grndes no implican convergencia, pero el converso no implica convergencia

--

3. Evaluación de cadenas: Correr $m$ cadenas paralelas y verificar que el comportamiento individual sea igual al global, así como la estabilidad de los estimadores ergódicos en cada una de las cadenas


--

4. $\hat{R}$: La idea detrás de este estadístico de prueba es dividir las $n$ simulaciones en $m_a$ y $m_b$ y estimar la varianza global del promedio ergódico con una combinación convexa dada por la partición $m_a$, $m_b$. Se acepta la convergecnia si $\hat{R} < 1.2$ según Gelman,1996. (Ver Gamerman, p.167)

--

Existen muchos otros métodos que apalancan cualidades estadísticas del resultado de la simulación, sin mebargo, los antes mencionados son los más populares y más estudiados por su aplicación general a cualquier procesos MCMC

---

class: inverse, center, middle

# 2

--

# Ejemplo de muestreo de Gibbs

---

class: center, middle

# [un ejemplo poisson](http://www.dme.ufrj.br/mcmc/)

---

# ¿Qué sigue?

--

1. Necesidad de software para análisis bayesiano

--

2. Stan y `RStan`



