---
title: "Métodos Estadísticos con R"
subtitle: "Stats 101"
author: "Gibrán Peniche"
date: "(versión 0.0.1) - 2020/06/05"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["xaringan-themer.css", "style.css"]
    nature:
      highlightStyle: github
      highlightLines: TRUE
      countIncrementalSlides: TRUE
      self_contained: TRUE
      ratio: '16:9'
    seal: false
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(eval = TRUE)
```

class: title-slide, middle

.pull-left[ 
# Métodos Estadísticos con R
## Stats 101
### Gibrán Peniche
### v. 0.0.1
### 2020-06-09
####  <i class="fab fa-github"></i> [jgpeniche](https://github.com/jgpeniche)
####  <i class="fab fa-twitter"></i> [PenicheGibran](https://twitter.com/PenicheGibran)
####  <i class="fab fa-google"></i> jgpeniche@gmail.com

]

.pull-right[

![](figs/logo_g.png)

]

---

class: inverse, center, middle
# ¿Porqué Estadística?


---

# Según [Drew Conway]([http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram)

```{r drew, echo=FALSE, out.width= '500px', out.height='500px', fig.align='center'}

knitr::include_graphics('figs/ds_diagram.png')
```

---

class: inverse, center, middle

# ¿Qué es la estadística?

---

class: middle, center



# En palabras de Manuel Mendoza...


---

class: middle

.pull-left[

```{r mendoza, fig.align='center', out.width=300, out.height=300, echo= FALSE}
knitr::include_graphics('figs/mendoza.jpg')

```

]



.pull-right[

## "Un conjunto de **técnicas** para describir **fenómenos** que se manifiestan a través de **datos** que presentan **aleatoriedad**"

]

---

# Un conjunto de técnicas...

<br>
<br>
<br>
## Entendemos que describirmos estos fenómenos a través de **resúmenes** que deben ser **suficentes** y **minimales**

---

class: inverse, middle, center
# Pero... ¿Para que "hacemos estadística"?
---

class: center, middle

## El fin último de la inferencia es **proveer** de información **confiable** para la **toma de decisiones** 

--

## En otras palabras las inferencias deben ser **ÓPTIMAS**

---

class: inverse, center, middle

# Algunos problemas con la estadística frecuentista...

---

class: center, middle, inverse

# 1

---

# ¿Qué es la probabilidad para la escuela de Fisher y Neyman?
--

$\rightarrow$ Es el **límite** de **frecuencias relativas** al repetir un experimento en las **mismas condiciones** una infinidad de veces

--

$$P(A) = \lim_{N\to\infty} \frac{a \epsilon A}{N}$$
--

$\rightarrow$ Esta definición proviene del **positivismo** de Auguste Comte

--

$\rightarrow$ En esta corriente se entiende a la **experiencia** cómo la **única** fuente de conociento.

---

<br>
<br>
<br>
<br>
## **Pregunta:**

### *¿Cuál es la probabilidad de que Benito Juárez haya nacido en Jueves?*

--

### ¿Acaso Benito Juárez puede nacer a veces en Jueves, otras en Domingo y algunas otras en Lunes?

---

class: center, middle, inverse
# 2

---

# $X \sim Bernoulli( \theta)$
--

**Problema:**


Estimar por regiones, usando el método pivotal, a $\theta$ suponiendo que tiene una muestra de tamaño $n$ donde **todas** las observaciones fueron exitos...

--

Sabemos que $\overline{X} = \hat{\theta} = 1$

--

$\rightarrow$ ¿Concluimos que **no** hay incertidumbre sobre nuestro parámetro?

--

$\rightarrow$ ¿Cómo incorporamos al procedimiento de inferencia que nosotros sabemos que el valor real del parámetro debe estar alrededor del 75%?

--

$\rightarrow$ ¿Disminuimos $\overline{X}$ a pesar de que en los datos no hay información sobre este hecho? ¿Y la incertumbre? ¿Cómo la incorporamos?

---

# $X \sim Bernoulli( \theta)$

Además, por el método pivotal...

$$ \frac{X - \theta}{\sqrt{ \theta \cdot (1 - \theta)}} \sim ?$$
--

$\rightarrow$ Sabemos que esto definitivamente **NO** es normal

--


$\rightarrow$ Si hacemos trampa, suponemos que es normal y resolviendo la ecuasión de segundo grado para $\theta$ vamos a obtener que $\theta \epsilon [ 1 \pm Z_{(1 -  \frac{ \alpha}{2})} \sqrt{\frac{1}{n^4}} ]$

--

$\rightarrow$ ¿Truncamos el intervalo en 1? (De hecho si  $n \rightarrow \infty$ se colapsa en 1)

--

$\rightarrow$ Este resultado persiste para otras aproximaciones al intervalo

---

class: center, middle, inverse
# 3

---

# Teorema de Fieller para cociente de medias

--

**Problema:** 


Estimar por regiones el cociente de medias para dos muestras con distribución normal...

--

**Problema más grande**

--

Se puede probar que


### $$\exists (1 - \alpha) < 1 .,. \rho = \frac{\mu_1}{\mu_2} \epsilon \mathbb{R}$$

--

$\rightarrow$ Tenemos un intervalo de confianza **FIJO** al nivel $(1 - \alpha) \cdot$ 100% $< 1$ que abarca todo el espacio parametral

---

# Más problemas

--

$\cdot$ Existen 2 estimadores **NO** Máximo Verosímiles que funcionan mejor en la práctica estimar la mediana la distribución *lognormal* que el estimador de MV

--

$\cdot$ Se puede probar que hay estimadores **insesgados** que estiman con probabilidad 0 eventos que en la distribución teórica tienen probabilidad distinta de 0

--

$\cdot$ La estimación de un fenómeno **aleatorio** en regresión líneal se reduce. o es equivalente, a un problema **geométrico** en el método tradicional de mínimos cuadrados, que además por el *Teorema de Gauss* los estimadores que obtenemos son únicos y además son insesgados

--

$\cdot$ En *teoría de valores extremos*, la estimación de los parametros se hace generalmente con estádisticas que no necesariamente son insesgadas o Máximo Verosímiles

---

# En conclusión

--

### La escuela frecuentista de Fisher - Neyman - Pearson nos da una serie de **criterios de optimalidad** (insesgamiento, consistencia en ECM, etc) 

--

### Estos criterios los entendemos en términos del **problema matemático** (Por eso se le conoce como **Estadística Matemática**) pero no en el contexto del *¿para qué?* de la inferencia

---

# En conclusión

### Además, estos criterios **dependen del problema de inferencia** que estemos tratando

--

### No tenemos un **procedimiento general** para hacer inferencia, ni un criterio general de optimalidad para nuestras inferencias

--

### Los padres de la estadística clásica **no lograron** establecer un cuerpo axiomático para consolidar a la estadística cómo una teoría en el primer cuarto del siglo XX
---

# El problema de toma de decisiones en ambiente de incertudumbre

--

<br> 

### Lo que nos generalmente nos interesa como profesionistas (economistas, actuarios, financieros, politologos, etc) es tener un **número** con el que podamos decidir nuestro siguiente paso y nos gustaría tener algún grado de certidumbre sobre ese número

---

class: center, middle

## **¿Cuál es la manera óptima de tomar decisiones en ambiente de incertidumbre?**
--

## **¿Existe algún criterio que nos asegure, sin importar las circunstancias, que nuestra inferencia es óptima?**
---

class: inverse, center, middle

# La Estadística Bayesiana nos provee de un procedimiento de inferencia ÓPTIMO para la toma de decisiones ante un ambiente de incertidumbre

---

class: center, middle

## **(Que si lo piensan bien, en realidad es nuestro día a día)**
---

# ¿Qué es la Estadística Bayesiana?

--

### Una **teoría de inferencia** para la toma de decisiones en el ambiente de incertidumbre

--

### Proviene de la corriente filosófica del **idealismo trascendetal** de Immanuel Kant en el siglo XIX

--

### Esta corriente (a grandes rasgos) propone conciliar a la razón y a la experiencia como fuentes de conocimiento

--

### Partiendo de lo anterior la Teoría Bayesiana entiende la probabilidad como una **medida de la ignorancia de uno mismo** con respecto a algún fenómeno, razón por la cual históricamente se la ha conocido cómo *probabilidad subjetiva*

---

# La necesidad de una teoría estadística

--

### Un indicador unívoco de la madurez de una **técnica** es cuando esta logra consolidarse cómo una teoría a través de la construcción un cuerpo axiomático

--

### En mi opinión la estadística es la herramienta por excelencia de la ciencia, ya que a través de ella se enfrenta la abstracción con el mundo real

--

### Al final, muchas decisiones (políticas públicas, medidas de control de medicamentos, regulación bancaria/financiera) descansan en tener cierto grado de certidumbre y de ellas dependen a veces millones de dolares/miles de empleos/ la salud de cierta población, etc...

--

### La estadística es la rama verdaderamente práctica de las matemáticas

---

# ¿Qué NO es la Estadística Bayesiana?

--

  + **NO** es tratar a los parámetros como variables aleatorias (El parámetro es **SIEMPRE FIJO** y **DESCONOCIDO**)

--

  + **NO** es `model.bayesian.fit`, hay que conocer la teoría detrás del procedimiento de inferencia (esto también es por ética profesional)

--

  + **NO** es *MCMC go prrrrrr*, hay que conocer sobre la teoría que está detrás de los métodos númericos (También aplica para la ciencia en general)
  
---
class: center, middle
# Breviario Histórico de los Bayesianos

---

# Un poco de historia...

--

### "Bayesianos" era un término que Fisher utilizaba para referirse despectivamente a los partidiarios de esta escuela

--

### Aunque hoy en día el teorema a partir del cual se contruye el procedimiento de inferencia que vamos aestudiar lleva por nombre el apellido del reverendo **Thomas Bayes**, fue en realidad **Pierre-Simon Laplace** quien desarrolló la expresión que hoy utlizamos en los cursos de cálculo de probabilidades y quien fué el verdadero precursor de esta corriente

--

### Aunque hoy en día la estadística bayesiana se ha vuelto popular debido a los avances en materia de poder de computo y consecuentemente a la popularización de los modelos de Machine Learning e Intelgencia artificial, lo cierto es que siempre ha estado allí...
---

# Un poco de historia...

 - Fue con métodos bayesianos que se descifraron los códigos ENIGMA alemanes (WWII)

--

 - Se uso ampliamente en la milicia en los manuales de artillería Ingleses y Americanos para apuntar cañones
 
--

 - Se utilizó para encontrar bombas nucleares perdidas en la guerra fría y para trazar trayectorias de balística contra submarinos rusos
  
--

 - Ha sido el común denominador entre la ciencias actuariales desde los tiempos de Edmun Halley
 
--

 - La BBC usó durante 20 años métodos bayesianos para estudiar la probabilidad de éxito de los condidatos a la presidencia de Estados Unidos
 
--

 - Personajes como Robert Schailfer desarrollaron manuales de negocios en Harvard con principios Bayesianos de Teoría de Decisión
 
---
class: middle, center

### **Obviamente, toda esta infromación era secreta...**
--

### **...mientras tanto Fisher y anexos se encargaron de desacreditar sistemáticamente esta corriente por muchos, muchos años**

---

# ¿Qué sigue?

### En las siguientes sesiones vamos a aprender:

--

  1. La definición de problema de decisión
  
--

  2. Los axiomas de coherencia
  
--

  3. Concluiremos que de acuerdo a los axiomas el criterio óptimo de toma de decisiones es el de **utilidad esperada**
  
--

  4. La inferencia cómo problema de decisión

--

  5. Estimadores de Pérdida Mínima, estimación puntual y por regiones (Modelos Conjugados)
  
--

  6. Pruebas de hipótesis

--

  7. Pronóstico
